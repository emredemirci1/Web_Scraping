{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "\n",
    "product_list = []\n",
    "a = 1\n",
    "\n",
    "while a <= 900:\n",
    "    print(f\"Page {a} is being processed...\")\n",
    "\n",
    "    \n",
    "    time.sleep(60)\n",
    "    \n",
    "    \n",
    "    r = requests.get(f\"https://www.hepsiemlak.com/satilik?page={a}\", headers=headers)\n",
    "    \n",
    "    \n",
    "    if r.status_code == 429:\n",
    "        print(f\"Page {a}: 429 Too Many Requests. This page is skipped.\")\n",
    "        a += 1\n",
    "        continue\n",
    "    elif r.status_code != 200:\n",
    "        print(f\"Page {a}: {r.status_code} error. Moving forward\")\n",
    "        a += 1\n",
    "        continue\n",
    "\n",
    "    soup = BeautifulSoup(r.content, \"lxml\")\n",
    "    page = soup.find(\"ul\", attrs={\"class\": \"list-items-container\"})\n",
    "    \n",
    "    \n",
    "    if page:\n",
    "        product = page.find_all(\"div\", attrs={\"class\": \"links\"})\n",
    "        for i in product:\n",
    "            link_end = i.a.get(\"href\")\n",
    "            link_start = \"https://www.hepsiemlak.com\"\n",
    "            link = link_start + link_end\n",
    "            print(link)\n",
    "\n",
    "            #\n",
    "            r1 = requests.get(link, headers=headers)\n",
    "\n",
    "            \n",
    "            if r1.status_code == 429:\n",
    "                print(f\"Error 429 in the product link. This product is skipped.\")\n",
    "                continue\n",
    "            elif r1.status_code != 200:\n",
    "                print(f\"Error {r1.status_code} in product link. This product is skipped.\")\n",
    "                continue\n",
    "\n",
    "            sp1 = BeautifulSoup(r1.content, \"lxml\")\n",
    "\n",
    "            try:\n",
    "                Price = sp1.find(\"div\", attrs={\"class\": \"right\"}).text.strip()\n",
    "                Location = sp1.find(\"ul\", attrs={\"class\": \"short-property\"})\n",
    "                \n",
    "                Şehir = np.nan\n",
    "                District = np.nan\n",
    "                Metre_Kare = np.nan\n",
    "\n",
    "                \n",
    "                if Location:\n",
    "                    li_elements = Location.find_all(\"li\", attrs={\"data-v-f9b3c830\": True})\n",
    "                    if len(li_elements) >= 2:\n",
    "                        City = li_elements[0].get_text(strip=True)\n",
    "                        District = li_elements[1].get_text(strip=True)\n",
    "                    if len(li_elements) >= 7:\n",
    "                        Metre_Kare = li_elements[6].get_text(strip=True)\n",
    "\n",
    "                \n",
    "                features = []\n",
    "                values = []\n",
    "                features_raw = sp1.find_all(\"li\", attrs={\"class\": \"spec-item\"})\n",
    "                for feature in features_raw:\n",
    "                    spans = feature.find_all(\"span\")\n",
    "                    if len(spans) == 2:\n",
    "                        feature_name = spans[0].get_text(strip=True)\n",
    "                        feature_value = spans[1].get_text(strip=True)\n",
    "                        \n",
    "                        features.append(feature_name)\n",
    "                        values.append(feature_value)\n",
    "\n",
    "                \n",
    "                feature_dict = dict(zip(features, values))\n",
    "                feature_dict[\"Şehir\"] = City\n",
    "                feature_dict[\"İlçe\"] = District\n",
    "                feature_dict[\"Fiyat\"] = Price\n",
    "                feature_dict[\"Metre_Kare\"] = Metre_Kare\n",
    "\n",
    "                product_list.append(feature_dict)\n",
    "\n",
    "            except Exception as e:\n",
    "                \n",
    "                feature_dict = {\n",
    "                    \"Şehir\": np.nan,\n",
    "                    \"İlçe\": np.nan,\n",
    "                    \"Fiyat\": np.nan,\n",
    "                    \"Metre_Kare\": np.nan\n",
    "                }\n",
    "                product_list.append(feature_dict)\n",
    "                print(f\"Error: {e}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Page {a} not found or content not available. Moving forward.\")\n",
    "    \n",
    "    \n",
    "    a += 1\n",
    "    print(f\"Moving to page {a}...\")\n",
    "\n",
    "\n",
    "df = pd.DataFrame(product_list).fillna(np.nan)\n",
    "\n",
    "\n",
    "selected_features = [\n",
    "    'Şehir', 'İlçe', 'Fiyat', 'Metre_Kare', 'Konut Tipi', 'Oda + Salon Sayısı',\n",
    "    'Bulunduğu Kat', 'Bina Yaşı', 'Isınma Tipi', 'Kat Sayısı',\n",
    "    'Eşya Durumu', 'Banyo Sayısı', 'Kira Getirisi'\n",
    "]\n",
    "df = df[selected_features]\n",
    "\n",
    "\n",
    "df.to_excel(\"Hepsi_Emlak.xlsx\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
